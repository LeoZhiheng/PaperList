# PaperList

Êï¥ÁêÜËøëÂÖ©Âπ¥Èñ±ËÆÄÁöÑ600+ÊñáÁ´†  
**Á¨¨‰∏ÄÈöéÊÆµ: ‰∏âÁ∂≠ÁõÆÊ®ôÊ™¢Ê∏¨/Ë∑üËπ§/ÂàÜÂâ≤Ôºå‰∫åÁ∂≠ÁõÆÊ®ôÊ™¢Ê∏¨/Ë∑üËπ§/ÂàÜÂâ≤ÔºåÊ∑±Â∫¶/ÂÖâÊµÅ‰º∞Ë®à**Á≠âÔºåÊñΩÂ∑•‰∏≠~~~~~~~~~~

(Âè™Êõ¥Êñ∞È†ÇÊúÉÈ†ÇÂàä)  
2023.4.20 Êõ¥Êñ∞19ÁØá 3D Object Detection (Multi-Frame Fusion, Radar), 3D Single Object Tracking  
2023.4.21 Êõ¥Êñ∞20ÁØá 3D Object Detection (Radar), 3D Single Object Tracking, 2D Single Object Tracking   
2023.4.22 Êõ¥Êñ∞24ÁØá 3D Object Detection (Radar), 2D Single Object Tracking  
2023.4.23 Êõ¥Êñ∞21ÁØá 3D Object Detection (LiDAR Range Image), 2D Single / Multi Object Tracking   
2023.4.24 Êõ¥Êñ∞16ÁØá 3D Object Detection (Weakly Supervised, Mono)...**Á™ÅÁ†¥100ÁØá**:star2::fire:üòÑ       
2023.4.25 Êõ¥Êñ∞20ÁØá 3D Object Detection (Stereo), Optical Flow    
2023.4.27 Êõ¥Êñ∞20ÁØá 3D Object Detection (Stereo), Stereo Matching, 3D Segmentation    
2023.4.28 Êõ¥Êñ∞5ÁØá 3D Object Detection (Stereo), Stereo Matching     
2023.4.30 Êõ¥Êñ∞20ÁØá 2D Object Detection, 3D Object Detection (Multi-view Images)     
2023.5.1  Êõ¥Êñ∞20ÁØá 3D Object Detection (Classic)

## Catalog

- [Optical Flow](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#optical-flow)   
- [Stereo Matching](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#stereo-matching)   
- [2D Object Detection](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#2D-object-detection) 
  - [Classic](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#classic) 
- [2D Object Tracking](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#2D-object-tracking) 
  - [2D Single Object Tracking](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#2D-single-object-tracking) 
  - [2D Multi Object Tracking](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#2D-multi-object-tracking) 
- [3D Object Detection](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#3d-object-detection) 
  - [Classic](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#classic-1)
  - [Multi-Frame Fusion](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#multi-frame-fusion)     
  - [Weakly Supervised](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#weakly-supervised)    
  - [LiDAR Range Image](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#liDAR-range-image)     
  - [Mono](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#mono)     
  - [Stereo](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#stereo)     
  - [Multi-view Images](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#multi-view-images)    
  - [Radar](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#radar)   
- [3D Object Tracking](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#3D-object-tracking) 
  - [3D Single Object Tracking](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#3D-single-object-tracking) 
- [3D Segmentation](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#3D-segmentation)     
  - [Classic](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#classic-2)     
  - [Moving Object Segmentation](https://github.com/LeoZhiheng/PaperList/blob/main/README.md#moving-object-segmentation)     

## Optical Flow

[Learning Optical Flow with Kernel Patch Attention](https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Learning_Optical_Flow_With_Kernel_Patch_Attention_CVPR_2022_paper.pdf) [2022 CVPR]    

[SKFlow: Learning Optical Flow with Super Kernels](https://arxiv.org/abs/2205.14623) [2022 NIPS]         

[FlowFormer: A Transformer Architecture for Optical Flow](https://arxiv.org/abs/2203.16194) [2022 ECCV]       

[Global Matching with Overlapping Attention for Optical Flow Estimation](https://arxiv.org/abs/2203.11335) [2022 CVPR]    

[Deep Equilibrium Optical Flow Estimation](https://arxiv.org/abs/2204.08442) [2022 CVPR]    

[Imposing Consistency for Optical Flow Estimation](https://arxiv.org/abs/2204.07262) [2022 CVPR]     

[Learning Optical Flow with Adaptive Graph Reasoning](https://arxiv.org/abs/2202.03857) [2022 AAAI]     

[GMFlow: Learning Optical Flow via Global Matching](https://arxiv.org/abs/2111.13680) [2022 CVPR]    

[CRAFT: Cross-Attentional Flow Transformer for Robust Optical Flow](https://arxiv.org/abs/2203.16896) [2022 CVPR]  

[Learning Optical Flow from a Few Matches](https://arxiv.org/abs/2104.02166) [2021 CVPR]    

[Separable Flow: Learning Motion Cost Volumes for Optical Flow Estimation](https://openaccess.thecvf.com/content/ICCV2021/html/Zhang_Separable_Flow_Learning_Motion_Cost_Volumes_for_Optical_Flow_Estimation_ICCV_2021_paper.html) [2021 ICCV]     

[Learning to Estimate Hidden Motions with Global Motion Aggregation](https://arxiv.org/abs/2104.02409) [2021 ICCV]    

[RAFT: Recurrent All-Pairs Field Transforms for Optical Flow](https://arxiv.org/abs/2003.12039) [2020 ECCV]       

[A Fusion Approach for Multi-Frame Optical Flow Estimation](https://arxiv.org/abs/1810.10066) [2019 WACV]    

[Volumetric Correspondence Networks for Optical Flow](http://papers.neurips.cc/paper/8367-volumetric-correspondence-networks-for-optical-flow) [2019 NIPS]     

[PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume](https://arxiv.org/abs/1709.02371) [2018 CVPR]         

[LiteFlowNet: A Lightweight Convolutional Neural Network for Optical Flow Estimation](https://arxiv.org/abs/1805.07036) [2018 CVPR]    

[FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks](https://arxiv.org/abs/1612.01925) [2017 CVPR]    


## Stereo Matching

[MobileStereoNet: Towards Lightweight Deep Networks for Stereo Matching](https://arxiv.org/abs/2203.11483) [2022 WACV]   

[Practical Stereo Matching via Cascaded Recurrent Network with Adaptive Correlation](https://arxiv.org/abs/2203.11483) [2022 CVPR]    

[Domain-invariant Stereo Matching Networks](https://arxiv.org/abs/1911.13287) [2022 ECVA]    

[Attention Concatenation Volume for Accurate and Efficient Stereo Matching](https://arxiv.org/abs/2203.02146) [2022 CVPR]   

[HITNet: Hierarchical Iterative Tile Refinement Network for Real-time Stereo Matching](https://arxiv.org/abs/2007.12140) [2021 CVPR]       

[RAFT-Stereo: Multilevel Recurrent Field Transforms for Stereo Matching](https://arxiv.org/abs/2109.07547) [2021 3DV]    

[Revisiting Stereo Depth Estimation From a Sequence-to-Sequence Perspective with Transformers](https://arxiv.org/abs/2011.02910) [2021 ICCV]  

[AANet: Adaptive Aggregation Network for Efficient Stereo Matching](https://arxiv.org/abs/2004.09548) [2020 CVPR]   

[Attention-Aware Feature Aggregation for Real-time Stereo Matching on Edge Devices](https://openaccess.thecvf.com/content/ACCV2020/html/Chang_Attention-Aware_Feature_Aggregation_for_Real-time_Stereo_Matching_on_Edge_Devices_ACCV_2020_paper.html) [2020 ACCV]   

[GA-Net: Guided Aggregation Net for End-to-end Stereo Matching](https://arxiv.org/abs/1904.06587) [2019 CVPR]

[Group-wise Correlation Stereo Network](https://arxiv.org/abs/1903.04025) [2019 CVPR]    

[Hierarchical Discrete Distribution Decomposition for Match Density Estimation](https://arxiv.org/abs/1812.06264) [2019 CVPR]   

[Learning for Disparity Estimation through Feature Constancy](https://arxiv.org/abs/1712.01039) [2018 CVPR]         

[Pyramid Stereo Matching Network](https://arxiv.org/abs/1803.08669) [2018 CVPR]    

[End-to-End Learning of Geometry and Context for Deep Stereo Regression](https://arxiv.org/abs/1703.04309) [2017 ICCV]    

[DeepStereo: Learning to Predict New Views from the World‚Äôs Imagery](https://arxiv.org/abs/1506.06825) [2016 CVPR]    

## 2D Object Detection
### Classic  

[VarifocalNet: An IoU-aware Dense Object Detector](https://arxiv.org/abs/2008.13367) [2021 CVPR]    

[Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection](https://arxiv.org/abs/2006.04388) [2020 CVPR]    

[Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression](https://arxiv.org/abs/1911.08287) [2020 AAAI]   

[Fast Point R-CNN](https://arxiv.org/abs/1908.02990) [2019 ICCV]     

[FCOS: Fully Convolutional One-Stage Object Detection](https://arxiv.org/abs/1904.01355) [2019 CVPR]       

[Objects as Points](https://arxiv.org/abs/1904.07850) [2019 CVPR]      

[ou Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640) [2018 CVPR]     

[YOLO9000: Better, Faster, Stronger Joseph](https://arxiv.org/abs/1612.08242) [2017 CVPR]      

[Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002) [2017 ICCV]    

[UnitBox: An Advanced Object Detection Network](https://arxiv.org/abs/1608.01471) [2016 ACM MM]     

## 2D Object Tracking
### 2D Single Object Tracking

[DropMAE: Masked Autoencoders with Spatial-Attention Dropout for Tracking Tasks](https://arxiv.org/abs/2304.00571) [2023 CVPR]   

[MixFormer: End-to-End Tracking with Iterative Mixed Attention](https://arxiv.org/abs/2203.11082) [2022 CVPR]    

[Towards Grand Unification of Object Tracking](https://arxiv.org/abs/2207.07078) [2022 ECCV]    

[Joint Feature Learning and Relation Modeling for Tracking: A One-Stream Framework](https://arxiv.org/abs/2203.11991) [2022 ECCV]       

[Towards Sequence-Level Training for Visual Tracking](https://arxiv.org/abs/2208.05810) [2022 ECCV]    

[FEAR: Fast, Efficient, Accurate and Robust Visual Tracker arXiv:2112.07957v1](https://arxiv.org/abs/2112.07957) [2022 ECCV]     

[AiATrack: Attention in Attention for Transformer Visual Tracking](https://arxiv.org/abs/2207.09603) [2022 ECCV]    

[SparseTT: Visual Tracking with Sparse Transformers](https://arxiv.org/abs/2205.03776) [2022 IJCAI]    

[High-Performance Discriminative Tracking with Transformers](https://ieeexplore.ieee.org/document/9710969) [2021 ICCV]  

[Graph Attention Tracking](https://arxiv.org/abs/2011.11204) [2021 CVPR]        

[Learning Target Candidate Association to Keep Track of What Not to Track](https://arxiv.org/abs/2103.16556) [2021 ICCV]   

[SiamRCR: Reciprocal Classification and Regression for Visual Object Tracking](https://arxiv.org/abs/2105.11237V) [2021 IJCAI]    

[Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking](https://arxiv.org/abs/2103.11681) [2021 CVPR]    

[Learn to Match: Automatic Matching Network Design for Visual Tracking](https://arxiv.org/abs/2108.00803) [2021 ICCV]    

[STMTrack: Template-free Visual Tracking with Space-time Memory Networks](https://arxiv.org/abs/2104.00324) [2021 CVPR]

[Saliency-Associated Object Tracking](https://arxiv.org/abs/2108.03637) [2021 ICCV]    

[MART: Motion-Aware Recurrent Neural Network for Robust Visual Tracking](https://ieeexplore.ieee.org/document/9423078) [2021 WACV]     

[Transformer Tracking](https://arxiv.org/abs/2103.15436) [2021 CVPR]     

[Learning Spatio-Temporal Transformer for Visual Tracking](https://arxiv.org/abs/2103.17154) [2021 ICCV]  

[High-Performance Long-Term Tracking with Meta-Updater](https://arxiv.org/abs/2004.00305) [2020 CVPR]     

[Siam R-CNN: Visual Tracking by Re-Detection](https://arxiv.org/abs/1911.12836) [2020 CVPR]    

[Optical Flow in Deep Visual Tracking](https://ojs.aaai.org/index.php/AAAI/article/view/6890) [2020 AAAI]     

[Siamese Box Adaptive Network for Visual Tracking](https://arxiv.org/abs/2003.06761) [2020 CVPR]    

[Tracking by Instance Detection: A Meta-Learning Approach](https://arxiv.org/abs/2004.00830) [2020 CVPR]        

[State-Aware Tracker for Real-Time Video Object Segmentation](https://arxiv.org/abs/2003.00482) [2020 CVPR]         

[Deformable Siamese Attention Networks for Visual Object Tracking](https://arxiv.org/abs/2004.06711) [2020 CVPR]    

[Tracking Objects as Points](https://arxiv.org/abs/2004.01177) [2020 ECCV]      

[Model-free Tracking with Deep Appearance and Motion Features Integration](https://arxiv.org/abs/1812.06418) [2019 WACV]   

[ATOM: Accurate Tracking by Overlap Maximization](https://arxiv.org/abs/1811.07628) [2019 CVPR]     

[Fast Online Object Tracking and Segmentation: A Unifying Approach](https://arxiv.org/abs/1901.01660) [2019 CVPR]      

[Deeper and Wider Siamese Networks for Real-Time Visual Tracking](https://arxiv.org/abs/1901.01660) [2019 CVPR]   

[SiamRPN: High Performance Visual Tracking with Siamese Region Proposal Network](https://arxiv.org/abs/1808.06048) [2018 CVPR]   

[Distractor-aware Siamese Networks for Visual Object Tracking](https://arxiv.org/abs/1808.06048) [2018 ECCV]  

[End-to-end Flow Correlation Tracking with Spatial-temporal Attention](https://arxiv.org/abs/1711.01124) [2018 CVPR]  

[GOTURN: Learning to Track at 100 FPS with Deep Regression Networks](https://arxiv.org/abs/1604.01802) [2016 ECCV]  

[Fully-Convolutional Siamese Networks for Object Tracking](https://arxiv.org/abs/1606.09549) [2016 ECCV]  

### 2D Multi Object Tracking  

[Multiple Object Tracking with Correlation Learning](https://arxiv.org/abs/2104.03541) [2021 CVPR]       

[Deep SORT: Simple online and realtime tracking with a deep association metric](https://arxiv.org/abs/1703.07402) [2018 ICIP]     

[SORT: Simple online and realtime tracking](https://arxiv.org/abs/1602.00763) [2016 ICIP]    

## 3D Object Detection    

### Classic       

[VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking](https://arxiv.org/abs/2303.11301) [2023 CVPR]    

[Not All Points Are Equal: Learning Highly Efficient Point-based Detectors for 3D LiDAR Point Clouds](https://arxiv.org/abs/2203.11139) [2022 CVPR]

[Rethinking IoU-based Optimization for Single-stage 3D Object Detection](https://arxiv.org/abs/2207.09332) [2022 ECCV]      

[Sparse Fuse Dense: Towards High Quality 3D Detection with Depth Completion arXiv:2203.09780v1](https://arxiv.org/abs/2203.09780) [2022 CVPR]

[AFDetV2: Rethinking the Necessity of the Second Stage for Object Detection from Point Clouds](https://arxiv.org/abs/2112.09205) [2022 AAAI]    

[AFDet: Anchor Free One Stage 3D Object Detection](https://arxiv.org/abs/2006.12671) [2020 CVPR]    

[CIA-SSD: Confident IoU-Aware Single-Stage Object Detector From Point Cloud](https://arxiv.org/abs/2012.03015) [2020 AAAI]    

[PV-RCNN: Point-Voxel Feature Set Abstraction for 3D Object Detection](https://arxiv.org/abs/1912.13192) [2020 ICCV]     

[3DSSD: Point-based 3D Single Stage Object Detector](https://arxiv.org/abs/2002.10187) [2020 CVPR]   

[MLCVNet: Multi-Level Context VoteNet for 3D Object Detection](https://arxiv.org/abs/2004.05679) [2020 CVPR]    

[Point-GNN: Graph Neural Network for 3D Object Detection in a Point Cloud](https://arxiv.org/abs/2003.01251) [2020 CVPR]    

[TANet: Robust 3D Object Detection from Point Clouds with Triple Attention](https://arxiv.org/abs/1912.05163) [2020 AAAI]     

[PointRCNN: 3D Object Proposal Generation and Detection from Point Cloud](https://arxiv.org/abs/1812.04244) [2019 CVPR]   

[STD: Sparse-to-Dense 3D Object Detector for Point Cloud Zetong](https://arxiv.org/abs/1907.10471) [2019 CVPR]     

[PointPillars: Fast Encoders for Object Detection from Point Clouds](https://arxiv.org/abs/1812.05784) [2019 CVPR]   

[SECOND: Sparsely Embedded Convolutional Detection](https://www.mdpi.com/1424-8220/18/10/3337) [2018 Sensors]     

[VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection](https://arxiv.org/abs/1711.06396) [2018 CVPR]      

[PIXOR: Real-time 3D Object Detection from Point Clouds](https://arxiv.org/abs/1902.06326) [2018 CVPR]     

[Frustum PointNets for 3D Object Detection from RGB-D Data](https://arxiv.org/abs/1711.08488) [2018 CVPR]    

[BirdNet: a 3D Object Detection Framework from LiDAR Information](https://arxiv.org/abs/1805.01195) [2018 ITSC]    

### Multi Frame Fusion

[MGTANet: Encoding Sequential LiDAR Points Using Long Short-Term Motion-Guided Temporal Attention for 3D Object Detection](https://arxiv.org/abs/2212.00442) [2022 AAAI]

[SWFormer: Sparse Window Transformer for 3D Object Detection in Point Clouds](https://arxiv.org/abs/2210.07372) [2022 ECCV]  

[CenterFormer: Center-based Transformer for 3D Object Detection](https://arxiv.org/abs/2209.05588) [2022 ECCV]  

[MPPNet: Multi-Frame Feature Intertwining with Proxy Points for 3D Temporal Object Detection](https://arxiv.org/abs/2205.05979) [2022 ECCV]  

[3D-MAN: 3D Multi-frame Attention Network for Object Detection](https://arxiv.org/abs/2012.12395) [2021 CVPR]  

[Fast and Furious: Real Time End-to-End 3D Detection, Tracking and Motion Forecasting with a Single Convolutional Net](https://arxiv.org/abs/2012.12395) [2018 CVPR]

### Weakly Supervised

[Weakly Supervised 3D Object Detection from Point Clouds](https://arxiv.org/abs/2007.13970) [2022 ACM MM]     

### LiDAR Range Image  

[Fully Convolutional One-Stage 3D Object Detection on LiDAR Range Images](https://arxiv.org/abs/2205.13764) [2022 NIPS]            

[VISTA: Boosting 3D Object Detection via Dual Cross-VIew SpaTial Attention](https://arxiv.org/abs/2203.09704) [2022 CVPR]    

[LaserFlow: Efficient and Probabilistic Object Detection and Motion Forecasting](https://arxiv.org/abs/2003.05982) [2021 RAL]    

[To the Point : Efficient 3D Object Detection in the Range Image with Graph Convolution Kernels](https://arxiv.org/abs/2106.13381) [2021 CVPR]    

[RangeIoUDet: Range Image based Real-Time 3D Object Detector Optimized by Intersection over Union](https://ieeexplore.ieee.org/document/9578898) [2021 CVPR]    

[RangeDet: In Defense of Range View for LiDAR-based 3D Object Detection](https://arxiv.org/abs/2103.10039) [2021 ICCV]           

[RSN: Range Sparse Net for Efficient, Accurate LiDAR 3D Object Detection](https://arxiv.org/abs/2106.13365) [2021 CVPR]    

[RV-FuseNet: Range View Based Fusion of Time-Series LiDAR Data for Joint 3D Object Detection and Motion Forecasting](https://arxiv.org/abs/2005.10863) [2021 IROS]     

[Range Conditioned Dilated Convolutions for Scale Invariant 3D Object Detection](https://arxiv.org/abs/2005.09927) [2020 CoRL]      

[LaserNet: An Efficient Probabilistic 3D Object Detector for Autonomous Driving](https://arxiv.org/abs/1903.08701) [2019 CVPR]      

### Mono

[MonoDETR: Depth-aware Transformer for Monocular 3D Object Detection](https://arxiv.org/abs/2203.13310) [2022 CVPR]      

[MonoDTR: Monocular 3D Object Detection with Depth-Aware Transformer](https://arxiv.org/abs/2203.10981) [2022 CVPR]     

[Densely Constrained Depth Estimator for Monocular 3D Object Detection](https://arxiv.org/abs/2207.10047) [2022 ECCV]     

[Categorical Depth Distribution Network for Monocular 3D Object Detection](https://arxiv.org/abs/2103.01100) [2021 CVPR]    

[Delving into Localization Errors for Monocular 3D Object Detection](https://arxiv.org/abs/2103.16237) [2021 CVPR]    

[Orthographic Feature Transform for Monocular 3D Object Detection](https://arxiv.org/abs/1811.08188) [2020 BMVC]     

[MonoGRNet: A Geometric Reasoning Network for Monocular 3D Object Localization](https://arxiv.org/abs/1811.10247) [2019 AAAI]       

[Pseudo-LiDAR from Visual Depth Estimation: Bridging the Gap in 3D Object Detection for Autonomous Driving](https://arxiv.org/abs/1812.07179) [2019 CVPR]  

[Multi-Level Fusion based 3D Object Detection from Monocular Images](https://ieeexplore.ieee.org/document/8578347) [2018 CVPR]  

### Stereo   

[SIDE: Center-based Stereo 3D Detector with Structure-aware Instance Depth Estimation](https://arxiv.org/abs/2108.09663) [2022 WACV]     

[YOLOStereo3D: A Step Back to 2D for Efficient Stereo 3D Detection](https://repository.hkust.edu.hk/ir/Record/1783.1-116327) [2021 RAL]    

[LIGA-Stereo: Learning LiDAR Geometry Aware Representations for Stereo-based 3D Detector](https://arxiv.org/abs/2108.08258) [2021 ICCV]    

[Disp R-CNN: Stereo 3D Object Detection via Shape Prior Guided Instance Disparity Estimation](https://arxiv.org/abs/2004.03572) [2020 CVPR]    

[Confidence Guided Stereo 3D Object Detection with Split Depth Estimation](https://arxiv.org/abs/2003.05505) [2020 IROS]   

[DSGN: Deep Stereo Geometry Network for 3D Object Detection](https://arxiv.org/abs/2001.03398) [2020 CVPR]    

[ZoomNet: Part-Aware Adaptive Zooming Neural Network for 3D Object Detection](https://arxiv.org/abs/2003.00529) [2020 AAAI]    

[Object-Centric Stereo Matching for 3D Object Detection](https://arxiv.org/abs/1909.07566) [2020 ICAR]     

[Pseudo-LiDAR from Visual Depth Estimation: Bridging the Gap in 3D Object Detection for Autonomous Driving](https://arxiv.org/abs/1812.07179) [2019 CVPR]   
 
[Stereo R-CNN based 3D Object Detection for Autonomous Driving](https://arxiv.org/abs/1902.09738) [2019 CVPR]     

[Triangulation Learning Network: from Monocular to Stereo 3D Object Detection](https://arxiv.org/abs/1906.01193) [2019 CVPR]    
 
[Pseudo-LiDAR++: Accurate Depth for 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/1906.06310) [2019 ICLR]   

[Stereo Vision-based Semantic 3D Object and Ego-motion Tracking for Autonomous Driving](https://arxiv.org/abs/1807.02062) [2018 ECCV]         

[3D Object Proposals Using Stereo Imagery for Accurate Object Class Detection](https://arxiv.org/abs/1608.07711) [2018 TPAMI]    

### Multi-view Images

[M2BEV: Multi-Camera Joint 3D Detection and Segmentation with Unified Birds-Eye View Representation](https://arxiv.org/abs/2204.05088) [2022 Arvix]   

[BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird‚Äôs-Eye View Representation](https://arxiv.org/abs/2205.13542) [2022 Arvix]     

[FUTR3D: A Unified Sensor Fusion Framework for 3D Detection](https://arxiv.org/abs/2203.10642) [2022 Arvix]   

[PETR: Position Embedding Transformation for Multi-View 3D Object Detection](https://arxiv.org/abs/2203.05625) [2022 ECCV]    

[BEVFormer: Learning Bird's-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers](https://arxiv.org/abs/2203.17270) [2022 ECCV]     

[BEVFusion: A Simple and Robust LiDAR-Camera Fusion Framework](https://arxiv.org/abs/2205.13790) [2022 NIPS]   

[BEVDepth: Acquisition of Reliable Depth for Multi-view 3D Object Detection](https://arxiv.org/abs/2206.10092) [2022 AAAI]    

[BEVDet: High-Performance Multi-Camera 3D Object Detection in Bird-Eye-View](https://arxiv.org/abs/2112.11790) [2021 Arvix]    

[DETR3D: 3D Object Detection from Multi-view Images via 3D-to-2D Queries](https://arxiv.org/abs/2110.06922) [2021 CORL]    

[Lift, Splat, Shoot: Encoding Images from Arbitrary Camera Rigs by Implicitly Unprojecting to 3D](https://arxiv.org/abs/2008.05711) [2020 ECCV]         

### Radar

[Modality-Agnostic Learning for Radar-Lidar Fusion in Vehicle Detection](https://ieeexplore.ieee.org/document/9879704) [Radar+LiDAR] [2022 CVPR]  

[RaLiBEV: Radar and LiDAR BEV Fusion Learning for Anchor Box Free Object Detection Systems](https://arxiv.org/abs/2211.06108) [Radar+LiDAR] [2022 TNNLS]  

[K-Radar: 4D Radar Object Detection for Autonomous Driving in Various Weather Conditions](https://arxiv.org/abs/2206.08171) [4D Radar] [2022 NIPS]  

[Robust Multimodal Vehicle Detection in Foggy Weather Using Complementary Lidar and Radar Signals](https://ieeexplore.ieee.org/document/9578621) [Radar+LiDAR] [CVPR 2021]   

[RPFA-Net: a 4D RaDAR Pillar Feature Attention Network for 3D Object Detection](https://ieeexplore.ieee.org/document/9564754) [4D Radar] [2021 ITSC]  

[Seeing Through Fog Without Seeing Fog: Deep Multimodal Sensor Fusion in Unseen Adverse Weather](https://arxiv.org/abs/1902.08913) [Radar+LiDAR+Camera] [2020 CVPR]  

[RadarNet: Exploiting Radar for Robust Perception of Dynamic Objects](https://arxiv.org/abs/2007.14366) [Radar+LiDAR] [2020 ECCV]  

## 3D Object Tracking
### 3D Single Object Tracking  

[A Lightweight and Detector-Free 3D Single Object Tracker on Point Clouds](https://arxiv.org/abs/2203.04232) [2023 TITS]  

[Spatio-Temporal Contextual Learning for Single Object Tracking on Point Clouds](https://ieeexplore.ieee.org/document/10011208) [2023 TNNLS]  

[CMT: Context-Matching-Guided Transformer for 3D Tracking in Point Clouds](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136820091.pdf) [2022 ECCV]   

[GLT-T: Global-Local Transformer Voting for 3D Single Object Tracking in Point Clouds](https://arxiv.org/abs/2211.10927) [2022 AAAI] 

[Implicit and Efficient Point Cloud Completion for 3D Single Object Tracking](https://arxiv.org/abs/2209.00522) [2022 RAL]   

[Exploiting More Information in Sparse Point Cloud for 3D Single Object Tracking](https://arxiv.org/abs/2210.00519) [2022 RAL] :star2::fire:  

[3D Single-Object Tracking with Spatial-Temporal Data Association](https://ieeexplore.ieee.org/document/9981905) [2022 IROS]  

[3D Siamese Transformer Network for Single Object Tracking on Point Clouds](https://arxiv.org/abs/2207.11995) [2022 ECCV]  

[Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds](https://arxiv.org/abs/2203.01730) [2022 CVPR]  

[PTTR: Relational 3D Point Cloud Object Tracking with Transformer](https://arxiv.org/abs/2112.02857) [2022 CVPR]  

[Temporal-aware Siamese Tracker : Integrate Temporal Context for 3D Object Tracking](https://openaccess.thecvf.com/content/ACCV2022/html/Lan_Temporal-aware_Siamese_Tracker_Integrate_Temporal_Context_for_3D_Object_Tracking_ACCV_2022_paper.html) [2022 ACCV]  

[Graph-Based Point Tracker for 3D Object Tracking in Point Clouds](https://ojs.aaai.org/index.php/AAAI/article/view/20101) [2022 AAAI]  

[MLVSNet: Multi-level Voting Siamese Network for 3D Visual Tracking](https://ieeexplore.ieee.org/document/9710975) [2021 ICCV]  

[3D Siamese Voxel-to-BEV Tracker for Sparse Point Clouds](https://arxiv.org/abs/2111.04426) [2021 NIPS]  

[Box-Aware Feature Enhancement for Single Object Tracking on Point Clouds](https://arxiv.org/abs/2108.04728) [2021 ICCV]   

[PTT: Point-Track-Transformer Module for 3D Single Object Tracking in Point Clouds](https://arxiv.org/abs/2108.06455) [2021 IROS] :star2::fire:

[Model-free Vehicle Tracking and State Estimation in Point Cloud Sequences](https://arxiv.org/abs/2103.06028) [2021 IROS]  

[3D Object Tracking with Transformer](https://arxiv.org/abs/2110.14921) [2021 BMVC] :star2::fire:  

[P2B: Point-to-box network for 3D object tracking in point clouds](https://arxiv.org/abs/2005.13888) [2020 CVPR]    

[F-Siamese Tracker: A Frustum-based Double Siamese Network for 3D Single Object Tracking](https://arxiv.org/abs/2010.11510) [2020 IROS]    

[Leveraging Shape Completion for 3D Siamese Tracking](https://arxiv.org/abs/1903.01784) [2019 CVPR]   

[Efficient Bird Eye View Proposals for 3D Siamese Tracking](https://arxiv.org/abs/1903.10168) [2019 BMVC]  


## 3D Segmentation
### Classic
[SemanticKITTI: A Dataset for Semantic Scene Understanding of LiDAR Sequences](https://arxiv.org/abs/1904.01416) [2019 ICCV]      

### Moving Object Segmentation

[Automatic Labeling to Generate Training Data for Online LiDAR-based Moving Object Segmentation](https://arxiv.org/abs/2201.04501) [2022 RAL]     

[Moving Object Segmentation in 3D LiDAR Data: A Learning-based Approach Exploiting Sequential Data](https://arxiv.org/abs/2105.08971) [2021 RAL]     


